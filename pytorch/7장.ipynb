{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 순환신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 기본 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 로드\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>순환신경망 개념 설명</h5>\n",
    "<a href=\"https://wikidocs.net/60690\">https://wikidocs.net/60690</a>\n",
    "<br>\n",
    "<img src=\"./images/rnn_image4_ver2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 파이썬으로 RNN 구현\n",
    "$h_t=tanh(W_xX_t+W_hh_{t-1}+b)$\n",
    "<br>\n",
    "$y_t=f(W_yh_t+b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27073798, 0.37646874, 0.77600677, 0.44690026],\n",
       "       [0.44388026, 0.77298242, 0.73875228, 0.32308485],\n",
       "       [0.66897255, 0.34497565, 0.39840769, 0.82127011]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = np.random.randn(3,4)\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "은닉상태 값:\n",
      "[[-0.57166436 -0.98670248 -0.82612591  0.04004308 -0.84764638 -0.79364865\n",
      "   0.98894637 -0.98986762]\n",
      " [-0.36904716 -0.77255695 -0.83953156  0.46763686 -0.65965302 -0.52689072\n",
      "   0.99766625 -0.97933114]\n",
      " [-0.91996562 -0.92072417 -0.98119166  0.67690757 -0.91332098 -0.57814044\n",
      "   0.99972124 -0.99557965]\n",
      " [-0.65475786 -0.87267675 -0.85722462  0.50980551 -0.86526455 -0.26168189\n",
      "   0.98597222 -0.96966675]\n",
      " [-0.96999724 -0.64508226 -0.99204274  0.80738749 -0.96299903 -0.38187911\n",
      "   0.99869592 -0.99022754]\n",
      " [-0.82143297 -0.98291944 -0.87101403  0.48743911 -0.94001867 -0.07285294\n",
      "   0.98502478 -0.98252842]\n",
      " [-0.64666021 -0.94224911 -0.86989271  0.42028443 -0.84359513 -0.48611411\n",
      "   0.9949679  -0.98445717]\n",
      " [-0.57765586 -0.70746655 -0.85817263  0.35010523 -0.85391536 -0.61993201\n",
      "   0.92850633 -0.95061561]\n",
      " [-0.97049019 -0.9918288  -0.97860413  0.49816004 -0.98354929 -0.55093509\n",
      "   0.98846221 -0.9939664 ]\n",
      " [-0.76104388 -0.97970669 -0.89313332  0.42412753 -0.89196374 -0.44346333\n",
      "   0.99673032 -0.99028719]]\n",
      "출력 값:\n",
      "[[0.7155268 ]\n",
      " [0.778664  ]\n",
      " [0.88292881]\n",
      " [0.89573182]\n",
      " [0.89597321]\n",
      " [0.93452054]\n",
      " [0.85396651]\n",
      " [0.76956529]\n",
      " [0.88297482]\n",
      " [0.87596169]]\n"
     ]
    }
   ],
   "source": [
    "timesteps = 10 # 시점의 수, 주식 예제에서는 주가 시퀀스의 개수\n",
    "input_size = 4 # 입력층의 뉴런의 수, 주식의 ohlv 데이터\n",
    "hidden_size = 8 # 은닉 상태의 뉴런의 수, 메모리 셀의 용량\n",
    "out_size = 1 # 출력 층의 뉴런의 수\n",
    "\n",
    "inputs = np.random.random((timesteps, input_size)) # 입력 값 \n",
    "hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉상태 값은 0\n",
    "\n",
    "Wx = np.random.randn(input_size, hidden_size) # 입력에 대한 가중치\n",
    "Wh = np.random.randn(hidden_size, hidden_size) # 은닉상태에 대한 가중치\n",
    "Bh = np.random.randn(hidden_size) # 은닉상태 편향\n",
    "Bo = np.random.randn(out_size) # 출력층의 편향\n",
    "Wy = np.random.randn(hidden_size, out_size) # 출력층 가중치\n",
    "\n",
    "hidden_state_stack=[]   # 은닉상태 값 리스트\n",
    "output_stack=[] # 출력 값 리스트\n",
    "# 순환 신경망 연산\n",
    "for t in range(timesteps):\n",
    "    ht = np.tanh(np.dot(inputs[t], Wx) + (np.dot(Wh, hidden_state_t) + Bh))\n",
    "    yt = sigmoid( np.dot(ht, Wy)+Bo)\n",
    "    print(ht.shape)\n",
    "    hidden_state_stack.append(list(ht))\n",
    "    output_stack.append(list(yt))\n",
    "\n",
    "print(\"은닉상태 값:\")\n",
    "print(np.stack(hidden_state_stack))\n",
    "print(\"출력 값:\")\n",
    "print(np.stack(output_stack))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.5 기본 순환 신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>0.722898</td>\n",
       "      <td>0.732351</td>\n",
       "      <td>0.745525</td>\n",
       "      <td>0.759235</td>\n",
       "      <td>2206.199951</td>\n",
       "      <td>0.242113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>0.763058</td>\n",
       "      <td>0.750069</td>\n",
       "      <td>0.769089</td>\n",
       "      <td>0.757866</td>\n",
       "      <td>2204.850098</td>\n",
       "      <td>0.274771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>0.751894</td>\n",
       "      <td>0.745714</td>\n",
       "      <td>0.769280</td>\n",
       "      <td>0.756456</td>\n",
       "      <td>2203.459961</td>\n",
       "      <td>0.241609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>0.755809</td>\n",
       "      <td>0.742538</td>\n",
       "      <td>0.764596</td>\n",
       "      <td>0.756415</td>\n",
       "      <td>2203.419922</td>\n",
       "      <td>0.215603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>0.731584</td>\n",
       "      <td>0.717777</td>\n",
       "      <td>0.739548</td>\n",
       "      <td>0.729669</td>\n",
       "      <td>2177.050049</td>\n",
       "      <td>0.197057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close    Adj Close    Volume\n",
       "0  2019-01-30  0.722898  0.732351  0.745525  0.759235  2206.199951  0.242113\n",
       "1  2019-01-31  0.763058  0.750069  0.769089  0.757866  2204.850098  0.274771\n",
       "2  2019-02-01  0.751894  0.745714  0.769280  0.756456  2203.459961  0.241609\n",
       "3  2019-02-07  0.755809  0.742538  0.764596  0.756415  2203.419922  0.215603\n",
       "4  2019-02-08  0.731584  0.717777  0.739548  0.729669  2177.050049  0.197057"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"./data/kospi.csv\")\n",
    "scaler = MinMaxScaler()\n",
    "# min max 스케일러를 사용하여 데이터를 0~1 사이의 값으로 보정해준다.\n",
    "df[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.fit_transform(df[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 데이터 만들기\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "inputs = df[['Open', 'High', 'Low', 'Volume']].values\n",
    "targets = df[['Close']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 5, 4]) torch.Size([200, 1])\n",
      "torch.Size([226, 5, 4]) torch.Size([226, 1])\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스 데이터 만들기\n",
    "def seq_data(x, y, seq_length):\n",
    "    # 데이터를 일정 길이 기준으로 잘라서 배열로 만들어 반환\n",
    "    # ex) x:[1,2,3,4,5], y:[1,2,3,4,5], seq_length=3  경우\n",
    "    # 배열의 첫번째 내용:  x_seq -> [1,2,3], y_seq -> 4\n",
    "    # 배열의 두번째 내용:  x_seq -> [2,3,4], y_seq -> 5\n",
    "    x_seq=[]\n",
    "    y_seq=[]\n",
    "    data_len = len(x)\n",
    "    for i in range(data_len-seq_length):        \n",
    "        x_seq.append(x[i: i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return torch.FloatTensor(np.array(x_seq)).to(device), torch.FloatTensor(np.array(y_seq)).to(device).view(-1, 1)\n",
    "    # y_seq를 view(-1,1) 로 2차원배열로 만든 것은 오차함수로 사용할 MSE Loss가 기본적으로 이차원 함수를 요구하기 때문\n",
    "\n",
    "split_num = 200\n",
    "sequence_length = 5\n",
    "x_seq, y_seq = seq_data(inputs, targets, sequence_length)\n",
    "x_train_seq = x_seq[:split_num]\n",
    "y_train_seq = y_seq[:split_num]\n",
    "x_test_seq = x_seq[split_num:]\n",
    "y_test_seq = y_seq[split_num:]\n",
    "print(x_train_seq.size(), y_train_seq.size())\n",
    "print(x_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 설정\n",
    "trainset = TensorDataset(x_train_seq, y_train_seq)\n",
    "testset = TensorDataset(x_test_seq, y_test_seq)\n",
    "batch_size = 20\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 구축에 필요한 하이퍼 파라미터 정의하기\n",
    "input_size = x_seq.size(2)\n",
    "num_layers = 2\n",
    "hidden_layer = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([426, 5, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "size = x_seq.size()\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 클래스 \n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, sequence_length, num_layers, device):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(hidden_size*sequence_length, 1), nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size()[0], self.hidden_size).to(self.device)\n",
    "        out , _ = self.rnn(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rfBasic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95d65aac4a209d7f6f477bff3bf0d30402813baf4a07fcd4786092f0b3bc81ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
