{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unsqueez() 함수 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.Size([2, 2])\n",
      "unsqueeze(0): \n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]]])\n",
      "torch.Size([1, 2, 2])\n",
      "unsqueeze(1): \n",
      "tensor([[[1., 1.]],\n",
      "\n",
      "        [[1., 1.]]])\n",
      "torch.Size([2, 1, 2])\n",
      "unsqueeze(2): \n",
      "tensor([[[1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.]]])\n",
      "torch.Size([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 지정한 위치에 차원하나를 추가\n",
    "# 예를 들어 2,2 텐서에 unsqueeze(0)를 수행하면 텐서의 맨 앞에 차원을 추가 => (1,2,2)\n",
    "tensor1 = torch.Tensor(np.ones((2,2)))\n",
    "print(\"Original:\")\n",
    "print(tensor1)\n",
    "print(tensor1.size())\n",
    "print(\"unsqueeze(0): \")\n",
    "usqz0 = tensor1.unsqueeze(0) \n",
    "print(usqz0)\n",
    "print(usqz0.size())\n",
    "print(\"unsqueeze(1): \")\n",
    "usqz1 = tensor1.unsqueeze(1)\n",
    "print(usqz1)\n",
    "print(usqz1.size())\n",
    "print(\"unsqueeze(2): \")\n",
    "usqz2 = tensor1.unsqueeze(2)\n",
    "print(usqz2)\n",
    "print(usqz2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 다층 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.1 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegress(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 선형회귀 모델 y = w*x+b 표현 입력: 1, 출력: 1\n",
    "        self.fc = nn.Linear(1, 1, bias=True)\n",
    "    def forward(self, x):\n",
    "        y = self.fc(x)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Workspace\\python_skills\\pytorch\\파이토치_베이직_예제(5장-6장).ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(\u001b[39mrange\u001b[39m(\u001b[39m15\u001b[39m))\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m# 입력 값\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39mx\u001b[39m+\u001b[39mtorch\u001b[39m.\u001b[39;49mrand(\u001b[39m15\u001b[39;49m,\u001b[39m1\u001b[39;49m) \u001b[39m# 정답\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m LinearRegress()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(range(15)).unsqueeze(1) # 입력 값\n",
    "y = 2*x+torch.rand(15,1) # 정답\n",
    "\n",
    "model = LinearRegress()\n",
    "learning_rate = 1e-3\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_stack = []\n",
    "for epoch in range(50):\n",
    "    # Pytorch는 기본설정에 옵티마이저의 gradients값들을 추후 역전파 시 가산시키도록 되어 있음,\n",
    "    # 이러한 미분값 가산방식은 RNN을 학습시킬 때 편리함, 그러나 기본적인 방식의 학습일 경우\n",
    "    # 학습이 한번 종료되면 반드시 옵티마이저의 이전 미분값을 zero_grad()로 초기화 하여 학습을 진행햐야 함\n",
    "    optimizer.zero_grad() # 최적화는 계산을 누적시키기 때문에 매 epoch 마다 zero_grad()를 통해 값을 초기화 해준다.\n",
    "    y_hat = model.forward(x)\n",
    "    loss = criterion(y, y_hat)    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_stack.append(loss.item())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(loss_stack)\n",
    "plt.title(\"Loss\")\n",
    "plt.subplot(122)\n",
    "plt.plot(y.numpy(), 'r.')\n",
    "plt.title(\"Prediction\")\n",
    "plt.plot(y_hat.detach().numpy(), 'b-') # grad(미분값)이 포함된 Tensor를 넘파이로 변환하기전에 detach()로 grad제거\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2 집값 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 클래스\n",
    "class TensorData(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = y_data.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 만들기\n",
    "df = pd.read_csv(\"./data/reg.csv\", index_col=[0])\n",
    "# 데이터 프레임을 넘파일 배열로\n",
    "X = df.drop('Price', axis=1).to_numpy()\n",
    "Y = df['Price'].to_numpy().reshape(-1, 1)\n",
    "# 훈련 데이터와 테스트 데이터 나누기 \n",
    "#  * 순서는 1)훈련X, 2)테스트X, 3)훈련Y, 4)테스트X\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 데이터 만들기\n",
    "trainset = TensorData(X_train, Y_train)\n",
    "trainLoader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testset = TensorData(X_test, Y_test)\n",
    "testLoader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(13, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))        \n",
    "        x = self.dropout(F.relu(self.fc2(x)))        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Workspace\\python_skills\\pytorch\\파이토치_베이직_예제(5장-6장).ipynb 셀 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 모델 학습하기\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m Regressor()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m, weight_decay\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m)\n",
      "\u001b[1;32mc:\\Workspace\\python_skills\\pytorch\\파이토치_베이직_예제(5장-6장).ipynb 셀 13\u001b[0m in \u001b[0;36mRegressor.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mLinear(\u001b[39m13\u001b[39;49m, \u001b[39m50\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m50\u001b[39m, \u001b[39m30\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/python_skills/pytorch/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B2%A0%EC%9D%B4%EC%A7%81_%EC%98%88%EC%A0%9C%285%EC%9E%A5-6%EC%9E%A5%29.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m30\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\crexy\\anaconda3\\envs\\rfBasic\\lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty((out_features, in_features), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "model = Regressor()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-7)\n",
    "# weight decay는 weight들의 값이 증가하는 것을 제한함으로써, \n",
    "# 모델의 복잡도를 감소시킴으로써 제한하는 기법, \n",
    "# 즉 weight를 decay(부식시킨다라는 의미를 조금 감량시키는 의미)시켜서 \n",
    "# Overfitting을 방지하는 기법\n",
    "# SGD 경우 Regualarization: (1-에타^람다)W - 에타*미분(MSE)\n",
    "# Regularization 수식에서 람다값이 weight_decay값임!\n",
    "\n",
    "loss_ = []\n",
    "minibatch_cnt = len(trainLoader) # 데이터로더에 포함된 미니배치의 갯수\n",
    "# ex) 데이터수: 1000, 배치사이즈: 25 => minibatch_cnt: 40 => 미니배치 데이터의 개수\n",
    "for i in range(400):\n",
    "    running_loss = 0.0\n",
    "    for data in trainLoader:\n",
    "        inputs, values = data\n",
    "        optimizer.zero_grad()\n",
    "        y = model.forward(inputs)\n",
    "        e = criterion(y, values)\n",
    "        e.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += e.item()\n",
    "    epoch_loss = running_loss/minibatch_cnt\n",
    "    loss_.append(epoch_loss)\n",
    "    if i % 40 == 0:\n",
    "        print(f\"Epoch: {i}, Loss: {epoch_loss}\")\n",
    "        \n",
    "plt.plot(loss_)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가하기\n",
    "def evaluateModel(dataloader):\n",
    "    predictions = torch.tensor([], dtype=torch.float)\n",
    "    actuals = torch.tensor([], dtype=torch.float)\n",
    "    with torch.no_grad(): # require_grad를 비활성화 시킴 => 역전파를 위해 사용하는 연산을 비활성화\n",
    "        model.eval() # 드롭아웃과 같이 과적합 방지를 위한 정규화 기법을 비활성화 시킴\n",
    "        for data in dataloader:\n",
    "            inputs, values = data\n",
    "            output = model.forward(inputs)\n",
    "            # predictions에 output 데이터를 누적시킴\n",
    "            # output 데이터가 (1, 32) 경우 axis=0으로 누적되면\n",
    "            # (1, 32) -> (2, 32) 처럼 0번째 차원을 기준으로 데이터가 누적됨\n",
    "            predictions = torch.cat((predictions, output), 0)\n",
    "            actuals = torch.cat((actuals, values), 0)\n",
    "    predictions = predictions.numpy()\n",
    "    actuals = actuals.numpy()\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, actuals))\n",
    "    return rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.08908578753471375, Test RMSE: 0.10730893164873123\n"
     ]
    }
   ],
   "source": [
    "train_loss = evaluateModel(trainLoader)\n",
    "test_loss = evaluateModel(testLoader)\n",
    "\n",
    "print(f\"Train RMSE: {train_loss}, Test RMSE: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5.1 교차 검증을 통한 집값 예측 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold: 0, train loss: 0.10626403144474075, validation loss:0.11219097673892975\n",
      "Kfold: 1, train loss: 0.060652537166520124, validation loss:0.08319053798913956\n",
      "Kfold: 2, train loss: 0.0423403420423471, validation loss:0.08519025892019272\n",
      "Test loss: 0.1447765827178955\n"
     ]
    }
   ],
   "source": [
    "validation_loss = []\n",
    "model = Regressor()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-7)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(trainset)):\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subdampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    trainloader = DataLoader(trainset, batch_size=32, sampler=train_subsampler)\n",
    "    valloader = DataLoader(trainset, batch_size=32, sampler=val_subdampler)\n",
    "\n",
    "    trainloss_stack = []\n",
    "    valloss_stack = []\n",
    "    for i in range(400):\n",
    "        #  훈련데이터로 학습수행\n",
    "        minibatch_cnt = len(trainloader)\n",
    "        minibatch_loss = 0.0\n",
    "        for data in trainloader:\n",
    "            inputs, values = data\n",
    "            model.zero_grad()\n",
    "            outputs = model.forward(inputs)\n",
    "            #loss = mean_squared_error(values, outputs)\n",
    "            loss = criterion(outputs, values)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            minibatch_loss += loss.item()\n",
    "        trainloss_stack.append( np.sqrt( minibatch_loss/minibatch_cnt) )\n",
    "\n",
    "    train_loss = np.array(trainloss_stack).mean()\n",
    "    # 검증 데이터로 평가 수행\n",
    "    val_loss = evaluateModel(valloader)\n",
    "\n",
    "    print(f\"Kfold: {fold}, train loss: {train_loss}, validation loss:{val_loss}\")\n",
    "\n",
    "test_loss = evaluateModel(testLoader)\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 모델 구조 및 가중치 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.1 모델구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor(\n",
      "  (fc1): Linear(in_features=13, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=30, bias=True)\n",
      "  (fc3): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.6.2 모델변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 13])\n",
      "torch.Size([50])\n",
      "torch.Size([30, 50])\n",
      "torch.Size([30])\n",
      "torch.Size([1, 30])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 13]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight.size(), model.fc1.bias.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight torch.Size([50, 13])\n",
      "fc1.bias torch.Size([50])\n",
      "fc2.weight torch.Size([30, 50])\n",
      "fc2.bias torch.Size([30])\n",
      "fc3.weight torch.Size([1, 30])\n",
      "fc3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 10, 50]             700\n",
      "            Linear-2               [-1, 10, 30]           1,530\n",
      "           Dropout-3               [-1, 10, 30]               0\n",
      "            Linear-4                [-1, 10, 1]              31\n",
      "================================================================\n",
      "Total params: 2,261\n",
      "Trainable params: 2,261\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (10, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rfBasic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95d65aac4a209d7f6f477bff3bf0d30402813baf4a07fcd4786092f0b3bc81ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
